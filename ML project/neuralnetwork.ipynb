{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dz/tmzcb2_j20bbp4pjqn9xwlvw0000gn/T/ipykernel_2807/3080862315.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data = data.replace({\n"
     ]
    }
   ],
   "source": [
    "data = data.replace({\n",
    "    'Yes': 1, 'No': 0, 'Male': 1, 'Female': 0,\n",
    "    'No, borderline diabetes': '0',\n",
    "    'Yes (during pregnancy)': '1'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dz/tmzcb2_j20bbp4pjqn9xwlvw0000gn/T/ipykernel_2807/113086705.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['MentalHealth'].fillna(data['MentalHealth'].mean(),inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data['MentalHealth'].fillna(data['MentalHealth'].mean(),inplace=True)\n",
    "selected_features = [\n",
    "    'AgeCategory', 'DiffWalking', 'Diabetic', 'PhysicalHealth', 'Stroke',\n",
    "    'Smoking','GenHealth',\n",
    "    'Sex', 'Race', 'BMI', 'SkinCancer', 'Asthma','MentalHealth'\n",
    "]\n",
    "X = data[selected_features]\n",
    "y = data['HeartDisease']\n",
    "# X = X.drop(columns=['MentalHealth'], axis=1)\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42, shuffle=True)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_order = ['18-24', '25-29', '30-34', '35-39', '40-44', '45-49', '50-54', '55-59', '60-64', '65-69', '70-74', '75-79', '80 or older']\n",
    "ordinal_encoder = OrdinalEncoder(categories=[age_order])\n",
    "X_train['AgeCategory'] = ordinal_encoder.fit_transform(X_train[['AgeCategory']])\n",
    "X_val['AgeCategory'] = ordinal_encoder.transform(X_val[['AgeCategory']])\n",
    "X_test['AgeCategory'] = ordinal_encoder.transform(X_test[['AgeCategory']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One-hot encode 'AgeCategory', 'Race', 'GenHealth' for all datasets\n",
    "X_train = pd.get_dummies(X_train, columns=['Race', 'GenHealth'], drop_first=True)\n",
    "X_val = pd.get_dummies(X_val, columns=['Race', 'GenHealth'], drop_first=True)\n",
    "X_test = pd.get_dummies(X_test, columns=['Race', 'GenHealth'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val = X_train.align(X_val, join='left', axis=1, fill_value=0)\n",
    "X_train, X_test = X_train.align(X_test, join='left', axis=1, fill_value=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7074 - loss: 0.5638 - val_accuracy: 0.7635 - val_loss: 0.4958\n",
      "Epoch 2/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 918us/step - accuracy: 0.7495 - loss: 0.5089 - val_accuracy: 0.7663 - val_loss: 0.4926\n",
      "Epoch 3/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 900us/step - accuracy: 0.7524 - loss: 0.5085 - val_accuracy: 0.7671 - val_loss: 0.4928\n",
      "Epoch 4/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 904us/step - accuracy: 0.7588 - loss: 0.4989 - val_accuracy: 0.7664 - val_loss: 0.4920\n",
      "Epoch 5/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 916us/step - accuracy: 0.7609 - loss: 0.4938 - val_accuracy: 0.7657 - val_loss: 0.4917\n",
      "Epoch 6/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 916us/step - accuracy: 0.7605 - loss: 0.4934 - val_accuracy: 0.7682 - val_loss: 0.4922\n",
      "Epoch 7/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 896us/step - accuracy: 0.7582 - loss: 0.4936 - val_accuracy: 0.7676 - val_loss: 0.4939\n",
      "Epoch 8/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 928us/step - accuracy: 0.7542 - loss: 0.4984 - val_accuracy: 0.7668 - val_loss: 0.4916\n",
      "Epoch 9/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 898us/step - accuracy: 0.7583 - loss: 0.4967 - val_accuracy: 0.7685 - val_loss: 0.4911\n",
      "Epoch 10/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 908us/step - accuracy: 0.7625 - loss: 0.4893 - val_accuracy: 0.7686 - val_loss: 0.4928\n",
      "Epoch 11/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 895us/step - accuracy: 0.7617 - loss: 0.4925 - val_accuracy: 0.7685 - val_loss: 0.4917\n",
      "Epoch 12/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 896us/step - accuracy: 0.7632 - loss: 0.4916 - val_accuracy: 0.7678 - val_loss: 0.4947\n",
      "Epoch 13/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 907us/step - accuracy: 0.7595 - loss: 0.4935 - val_accuracy: 0.7660 - val_loss: 0.4929\n",
      "Epoch 14/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 899us/step - accuracy: 0.7640 - loss: 0.4918 - val_accuracy: 0.7663 - val_loss: 0.4918\n",
      "Epoch 15/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 913us/step - accuracy: 0.7607 - loss: 0.4931 - val_accuracy: 0.7663 - val_loss: 0.4923\n",
      "Epoch 16/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 938us/step - accuracy: 0.7615 - loss: 0.4938 - val_accuracy: 0.7665 - val_loss: 0.4917\n",
      "Epoch 17/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 912us/step - accuracy: 0.7611 - loss: 0.4932 - val_accuracy: 0.7644 - val_loss: 0.4924\n",
      "Epoch 18/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 893us/step - accuracy: 0.7608 - loss: 0.4919 - val_accuracy: 0.7671 - val_loss: 0.4921\n",
      "Epoch 19/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 915us/step - accuracy: 0.7621 - loss: 0.4895 - val_accuracy: 0.7674 - val_loss: 0.4916\n",
      "Epoch 20/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 896us/step - accuracy: 0.7610 - loss: 0.4908 - val_accuracy: 0.7660 - val_loss: 0.4924\n",
      "Epoch 21/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 913us/step - accuracy: 0.7601 - loss: 0.4902 - val_accuracy: 0.7682 - val_loss: 0.4920\n",
      "Epoch 22/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 899us/step - accuracy: 0.7668 - loss: 0.4850 - val_accuracy: 0.7676 - val_loss: 0.4922\n",
      "Epoch 23/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 942us/step - accuracy: 0.7595 - loss: 0.4932 - val_accuracy: 0.7660 - val_loss: 0.4916\n",
      "Epoch 24/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 893us/step - accuracy: 0.7653 - loss: 0.4862 - val_accuracy: 0.7673 - val_loss: 0.4924\n",
      "Epoch 25/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 910us/step - accuracy: 0.7634 - loss: 0.4903 - val_accuracy: 0.7679 - val_loss: 0.4920\n",
      "Epoch 26/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 895us/step - accuracy: 0.7644 - loss: 0.4863 - val_accuracy: 0.7671 - val_loss: 0.4929\n",
      "Epoch 27/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 910us/step - accuracy: 0.7638 - loss: 0.4889 - val_accuracy: 0.7677 - val_loss: 0.4916\n",
      "Epoch 28/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 891us/step - accuracy: 0.7625 - loss: 0.4879 - val_accuracy: 0.7667 - val_loss: 0.4936\n",
      "Epoch 29/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 936us/step - accuracy: 0.7627 - loss: 0.4915 - val_accuracy: 0.7676 - val_loss: 0.4923\n",
      "Epoch 30/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 887us/step - accuracy: 0.7620 - loss: 0.4886 - val_accuracy: 0.7676 - val_loss: 0.4930\n",
      "Epoch 31/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 910us/step - accuracy: 0.7611 - loss: 0.4888 - val_accuracy: 0.7678 - val_loss: 0.4926\n",
      "Epoch 32/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 898us/step - accuracy: 0.7642 - loss: 0.4857 - val_accuracy: 0.7680 - val_loss: 0.4927\n",
      "Epoch 33/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 898us/step - accuracy: 0.7615 - loss: 0.4912 - val_accuracy: 0.7676 - val_loss: 0.4925\n",
      "Epoch 34/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 907us/step - accuracy: 0.7594 - loss: 0.4906 - val_accuracy: 0.7664 - val_loss: 0.4923\n",
      "Epoch 35/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 897us/step - accuracy: 0.7643 - loss: 0.4844 - val_accuracy: 0.7665 - val_loss: 0.4932\n",
      "Epoch 36/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 954us/step - accuracy: 0.7660 - loss: 0.4816 - val_accuracy: 0.7671 - val_loss: 0.4929\n",
      "Epoch 37/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 889us/step - accuracy: 0.7619 - loss: 0.4883 - val_accuracy: 0.7672 - val_loss: 0.4931\n",
      "Epoch 38/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 911us/step - accuracy: 0.7627 - loss: 0.4855 - val_accuracy: 0.7675 - val_loss: 0.4950\n",
      "Epoch 39/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 899us/step - accuracy: 0.7622 - loss: 0.4864 - val_accuracy: 0.7668 - val_loss: 0.4929\n",
      "Epoch 40/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 950us/step - accuracy: 0.7665 - loss: 0.4862 - val_accuracy: 0.7664 - val_loss: 0.4939\n",
      "Epoch 41/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 895us/step - accuracy: 0.7658 - loss: 0.4832 - val_accuracy: 0.7662 - val_loss: 0.4943\n",
      "Epoch 42/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 913us/step - accuracy: 0.7623 - loss: 0.4861 - val_accuracy: 0.7688 - val_loss: 0.4962\n",
      "Epoch 43/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 896us/step - accuracy: 0.7693 - loss: 0.4807 - val_accuracy: 0.7671 - val_loss: 0.4936\n",
      "Epoch 44/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 906us/step - accuracy: 0.7625 - loss: 0.4912 - val_accuracy: 0.7686 - val_loss: 0.4932\n",
      "Epoch 45/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 893us/step - accuracy: 0.7678 - loss: 0.4812 - val_accuracy: 0.7669 - val_loss: 0.4941\n",
      "Epoch 46/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 941us/step - accuracy: 0.7612 - loss: 0.4897 - val_accuracy: 0.7672 - val_loss: 0.4945\n",
      "Epoch 47/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 892us/step - accuracy: 0.7617 - loss: 0.4874 - val_accuracy: 0.7665 - val_loss: 0.4937\n",
      "Epoch 48/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 908us/step - accuracy: 0.7593 - loss: 0.4910 - val_accuracy: 0.7671 - val_loss: 0.4931\n",
      "Epoch 49/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 891us/step - accuracy: 0.7639 - loss: 0.4844 - val_accuracy: 0.7674 - val_loss: 0.4946\n",
      "Epoch 50/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 914us/step - accuracy: 0.7605 - loss: 0.4909 - val_accuracy: 0.7657 - val_loss: 0.4942\n",
      "Epoch 51/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 918us/step - accuracy: 0.7611 - loss: 0.4879 - val_accuracy: 0.7673 - val_loss: 0.4945\n",
      "Epoch 52/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 917us/step - accuracy: 0.7726 - loss: 0.4793 - val_accuracy: 0.7675 - val_loss: 0.4966\n",
      "Epoch 53/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 891us/step - accuracy: 0.7624 - loss: 0.4868 - val_accuracy: 0.7662 - val_loss: 0.4940\n",
      "Epoch 54/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 916us/step - accuracy: 0.7631 - loss: 0.4878 - val_accuracy: 0.7677 - val_loss: 0.4943\n",
      "Epoch 55/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 894us/step - accuracy: 0.7613 - loss: 0.4888 - val_accuracy: 0.7663 - val_loss: 0.4935\n",
      "Epoch 56/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 938us/step - accuracy: 0.7666 - loss: 0.4852 - val_accuracy: 0.7642 - val_loss: 0.4960\n",
      "Epoch 57/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 891us/step - accuracy: 0.7665 - loss: 0.4845 - val_accuracy: 0.7675 - val_loss: 0.4969\n",
      "Epoch 58/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 913us/step - accuracy: 0.7632 - loss: 0.4840 - val_accuracy: 0.7654 - val_loss: 0.4939\n",
      "Epoch 59/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 900us/step - accuracy: 0.7641 - loss: 0.4842 - val_accuracy: 0.7662 - val_loss: 0.4947\n",
      "Epoch 60/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 915us/step - accuracy: 0.7635 - loss: 0.4861 - val_accuracy: 0.7639 - val_loss: 0.4945\n",
      "Epoch 61/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 926us/step - accuracy: 0.7671 - loss: 0.4800 - val_accuracy: 0.7662 - val_loss: 0.4950\n",
      "Epoch 62/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 892us/step - accuracy: 0.7638 - loss: 0.4850 - val_accuracy: 0.7654 - val_loss: 0.4938\n",
      "Epoch 63/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 913us/step - accuracy: 0.7632 - loss: 0.4884 - val_accuracy: 0.7684 - val_loss: 0.4957\n",
      "Epoch 64/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 896us/step - accuracy: 0.7612 - loss: 0.4891 - val_accuracy: 0.7677 - val_loss: 0.4942\n",
      "Epoch 65/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 918us/step - accuracy: 0.7641 - loss: 0.4838 - val_accuracy: 0.7671 - val_loss: 0.4951\n",
      "Epoch 66/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 920us/step - accuracy: 0.7610 - loss: 0.4889 - val_accuracy: 0.7681 - val_loss: 0.4944\n",
      "Epoch 67/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 909us/step - accuracy: 0.7660 - loss: 0.4861 - val_accuracy: 0.7671 - val_loss: 0.4943\n",
      "Epoch 68/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 898us/step - accuracy: 0.7617 - loss: 0.4890 - val_accuracy: 0.7662 - val_loss: 0.4944\n",
      "Epoch 69/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 907us/step - accuracy: 0.7653 - loss: 0.4844 - val_accuracy: 0.7672 - val_loss: 0.4941\n",
      "Epoch 70/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 890us/step - accuracy: 0.7615 - loss: 0.4878 - val_accuracy: 0.7653 - val_loss: 0.4957\n",
      "Epoch 71/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 988us/step - accuracy: 0.7653 - loss: 0.4864 - val_accuracy: 0.7658 - val_loss: 0.4944\n",
      "Epoch 72/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 891us/step - accuracy: 0.7631 - loss: 0.4853 - val_accuracy: 0.7659 - val_loss: 0.4955\n",
      "Epoch 73/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 907us/step - accuracy: 0.7679 - loss: 0.4832 - val_accuracy: 0.7654 - val_loss: 0.4965\n",
      "Epoch 74/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 891us/step - accuracy: 0.7634 - loss: 0.4854 - val_accuracy: 0.7674 - val_loss: 0.4950\n",
      "Epoch 75/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 936us/step - accuracy: 0.7659 - loss: 0.4815 - val_accuracy: 0.7670 - val_loss: 0.4954\n",
      "Epoch 76/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 893us/step - accuracy: 0.7640 - loss: 0.4839 - val_accuracy: 0.7677 - val_loss: 0.4952\n",
      "Epoch 77/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 903us/step - accuracy: 0.7613 - loss: 0.4889 - val_accuracy: 0.7664 - val_loss: 0.4953\n",
      "Epoch 78/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 891us/step - accuracy: 0.7675 - loss: 0.4817 - val_accuracy: 0.7669 - val_loss: 0.4948\n",
      "Epoch 79/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7682 - loss: 0.4818 - val_accuracy: 0.7682 - val_loss: 0.4960\n",
      "Epoch 80/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 889us/step - accuracy: 0.7654 - loss: 0.4849 - val_accuracy: 0.7643 - val_loss: 0.4960\n",
      "Epoch 81/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 907us/step - accuracy: 0.7669 - loss: 0.4819 - val_accuracy: 0.7656 - val_loss: 0.4963\n",
      "Epoch 82/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 895us/step - accuracy: 0.7651 - loss: 0.4810 - val_accuracy: 0.7657 - val_loss: 0.4948\n",
      "Epoch 83/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 914us/step - accuracy: 0.7680 - loss: 0.4794 - val_accuracy: 0.7661 - val_loss: 0.4954\n",
      "Epoch 84/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 915us/step - accuracy: 0.7637 - loss: 0.4832 - val_accuracy: 0.7646 - val_loss: 0.4958\n",
      "Epoch 85/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 905us/step - accuracy: 0.7627 - loss: 0.4878 - val_accuracy: 0.7659 - val_loss: 0.4971\n",
      "Epoch 86/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 890us/step - accuracy: 0.7587 - loss: 0.4847 - val_accuracy: 0.7659 - val_loss: 0.4956\n",
      "Epoch 87/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 910us/step - accuracy: 0.7652 - loss: 0.4792 - val_accuracy: 0.7660 - val_loss: 0.4955\n",
      "Epoch 88/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 912us/step - accuracy: 0.7673 - loss: 0.4816 - val_accuracy: 0.7649 - val_loss: 0.4962\n",
      "Epoch 89/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 918us/step - accuracy: 0.7617 - loss: 0.4853 - val_accuracy: 0.7649 - val_loss: 0.4973\n",
      "Epoch 90/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 888us/step - accuracy: 0.7639 - loss: 0.4872 - val_accuracy: 0.7640 - val_loss: 0.4966\n",
      "Epoch 91/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 904us/step - accuracy: 0.7644 - loss: 0.4835 - val_accuracy: 0.7651 - val_loss: 0.4959\n",
      "Epoch 92/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 918us/step - accuracy: 0.7696 - loss: 0.4813 - val_accuracy: 0.7653 - val_loss: 0.4966\n",
      "Epoch 93/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 893us/step - accuracy: 0.7698 - loss: 0.4792 - val_accuracy: 0.7658 - val_loss: 0.4958\n",
      "Epoch 94/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 904us/step - accuracy: 0.7685 - loss: 0.4785 - val_accuracy: 0.7661 - val_loss: 0.4980\n",
      "Epoch 95/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 894us/step - accuracy: 0.7624 - loss: 0.4853 - val_accuracy: 0.7649 - val_loss: 0.4959\n",
      "Epoch 96/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 944us/step - accuracy: 0.7674 - loss: 0.4786 - val_accuracy: 0.7677 - val_loss: 0.4957\n",
      "Epoch 97/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 892us/step - accuracy: 0.7677 - loss: 0.4808 - val_accuracy: 0.7659 - val_loss: 0.4960\n",
      "Epoch 98/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 904us/step - accuracy: 0.7677 - loss: 0.4804 - val_accuracy: 0.7655 - val_loss: 0.4955\n",
      "Epoch 99/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 888us/step - accuracy: 0.7658 - loss: 0.4827 - val_accuracy: 0.7641 - val_loss: 0.4962\n",
      "Epoch 100/100\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 941us/step - accuracy: 0.7678 - loss: 0.4802 - val_accuracy: 0.7665 - val_loss: 0.4959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.77\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, input_dim=X_train.shape[1], activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid') \n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
    "\n",
    "model.save(\"heart_disease_ann_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.73      0.77      6407\n",
      "           1       0.72      0.81      0.76      5407\n",
      "\n",
      "    accuracy                           0.77     11814\n",
      "   macro avg       0.77      0.77      0.77     11814\n",
      "weighted avg       0.77      0.77      0.77     11814\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4699, 1708],\n",
       "       [1051, 4356]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
